\section{The AdaptUIOnt Ontology}
\label{sec:adaptui_model}

As said before, the AdaptUI platform is supported by two pillars: an ontology
that models several significant concepts of the domain, and a set of rules
that trigger several modifications of these concepts. In this section the
AdaptUIOnt ontology, which represents the existing concepts in the user
interface adaptation domain, is presented.
  
The AdaptUIOnt ontology arises from the need of an adaptation model which gathers
knowledge of the \textit{user} capabilities, the \textit{context} that surrounds
the user, and the mobile \textit{device} the the user manipulates. The main goal
is to obtain a user interface adaptation personalized exclusively for the
characteristics of these three entities at the end of an adaptation process.

Through the following sections the AdaptUIOnt model is unfolded as follows: 
First, an introduction about the model is performed (see Section~\ref{sec:model_introduction}).
This introduction answers two design questions: \textit{how} the ontology has
been designed and \textit{why} several design decisions were made. The answers
bring several distinguishing aspects from the existing models found in the
literature (see Chapter~\ref{cha:state_of_the_art}). Next, in Section~\ref{sec:model_detail}
an answer to the question \textit{what} is given. The AdaptUIOnt ontology models
several primary and secondary groups of entities and knowledge. The primary
set of entities are grouped in the \textit{Entities Model}, explained in
Section~\ref{sec:entities_model}. The second group are contained in the
\textit{Dynamic Entities}, explained in Section~\ref{sec:dynamic_model}. Besides,
AdaptUIOnt describes several concepts and supports a set of rules which trigger
different actions (see Section~\ref{sec:adaptui_rules}).


\subsection{Introducing AdaptUIOnt: The \textit{Hows} and the \textit{Whys}}
\label{sec:model_introduction}

The literature analysis made in Chapter~\ref{cha:state_of_the_art} exposes
several possibilities regarding the problem of choosing the best technique
to model a user interface adaptation process and all the required knowledge
around it. As it will be explained later in the conclusions of this chapter, we
found that using ontologies would bring several benefits to our proposal. In 
this section we explain \textit{how} and \textit{why} the AdaptUIOnt ontology 
has been designed.

Many ontology based solutions take users as entities described by their physiological
capabilities~\citep{gregor_designing_2002}~\citep{razmerita_ontology_based_2003}
\citep{pereira_triple_2005}~\citep{persad_characterising_2007}~\citep{persad_cognitive_2007}
and~\citep{skillen2012ontological}. Moreover, facing adaptation or personalization
problems these solutions aim to cover not only capabilities but also disabilities.
When AdaptUIOnt was conceived, we found that modelling physiological abilities
was not practical. Although many users may have similar preferences and capabilities,
their tastes may differ. Besides, their reactions facing several problems may not
be the same. In addition, we realised how difficult it is to model each user
physiological characteristics without an expert's support. As scientists in the
computing domain we lack of this kind of physiological knowledge about individuals.
Thus, we believe we cannot face modelling user capabilities and also contemplating
and analysing their behaviour and responses.

Nevertheless,~\citet{casas_user_2008} described a taxonomy where user disabilities
are not explicitly contemplated. Instead of that, user preferences are classified
under several concepts, as is shown in Figure~\ref{fig:casas}. Through the taxonomy
represented by this figure it is shown how the authors avoid the modelling of
physiological capabilities of the user, centring the model in several preferences.
More information about the considerations of Casas et al. are given in
Section~\ref{sec:casas}.


\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{../figures/PDF/casas.pdf}
\caption{User profile taxonomy by~\citet{casas_user_2008}.}
\label{fig:casas}
\end{figure}

AdaptUIOnt is built under this idea, extending it and avoiding the modelling of
any explicit physiological characteristics. As it will be depicted in this chapter
several concepts changed in our proposal. Besides, several remarkable ontologies
from other authors are also used to enrich the AdaptUIOnt knowledge. For example,
the \ac{foaf} ontology~\citep{foaf} has been linked to complete the information 
of the user. The same happens with the \ac{gumo}~\citep{heckmann_gumogeneral_2005}, 
which also models information about the user. Although not all classes are 
included, several have been imported in the final version of the AdaptUIOnt 
model, as they might represent significant concepts for other developers. 
For example, in the \ac{gumo} ontology there is a class which models the user 
emotional state (\textit{Basic User Dimensions} $\rightarrow$ 
\textit{Emotional State}) through five basic emotions. In  the current AdaptUIOnt 
version these emotions are not considered for the adaptations. However, we believe
that other developers may consider that being under an \textit{anxiety} condition
might change or modify the result or the adaptation process. Every ontology that
has been used to complete the AdaptUIOnt ontology is shown in Table~\ref{tbl:used_ontologies}.

\begin{table}[H]
  \caption{Imported ontologies to complete several concepts of the AdaptUIOnt
  ontology: \ac{gumo}, \ac{foaf} and \ac{cobra}.}
 \label{tbl:used_ontologies}
\footnotesize
\centering
 \begin{tabular}{l l l l}
  \hline 
  \textbf{Ontology} 		& \textbf{Class}		& \textbf{Description}		& \textbf{Imported subclasses}		\\
  \hline
  \ac{gumo}~\citep{heckmann_gumogeneral_2005}& \textit{Basic User Dimensions}& It originally models 	& \textit{Ability And Proficiency},\\
				& 				& different aspects of 		& \textit{Characteristics},		\\
				& 				& the user, as certain 		& \textit{Contact Information},		\\
				&				& abilities, emotional 		& \textit{Demographics},		\\
				&				& status, and so on.		& \textit{Motion}, \textit{Role},	\\
  				& 				&  				& \textit{Emotional State},		\\
  				& 				&  				& \textit{Personality}, \textit{Mental}	\\
  				& 				&  				& \textit{State}, \textit{Physiological}\\
  				& 				&  				& \textit{State}			\\
  				& \textit{Context Information}	& It represents several		& \textit{Location} and \textit{Physical}\\
  				&				& concepts related to 		& \textit{Environment} and \textit{Social}\\
  				&				& the environment.		& \textit{Environment}.			\\
  \ac{foaf}~\citep{foaf}	& \textit{Document}		&  	 			& \textit{Image} and 			\\  
				& 				&				& \textit{PersonalProfileDocument}.	\\
				& \textit{SocialInstitution}	& 				& 					\\
				& \textit{OnlineAccount}	& 				& \textit{Online Chat Account},		\\
				& 				&				& \textit{Online E-commerce} 		\\
				& 				&				& \textit{Account} and \textit{Online} 	\\
				& 				&				& \textit{Gaming Account}.		\\
  \ac{cobra}~\citep{cobra}	& \textit{DeviceMemory}		& 				& 					\\
				& \textit{DisplayScreen}	& 				& 					\\
				& \textit{DisplayScreenResolution}& 				& 					\\
				& \textit{MemoryUsageType}	& 				& 					\\
  \hline
  
\end{tabular}
\end{table}


Other works have also been taken into account for the user model. For example
~\citet{gregor_designing_2002} consider that users (in this case, the elderly)
evolve and their capabilities might change not just because of their experience
but because of the context influence. For Gregor et al. elderly's capabilities
decrease due to their ageing. In this dissertation, this evolution of the user
capabilities is considered to be based on the context conditions and experience.
This is explained in Section~\ref{sec:adaptation_polisher}, in which a concrete
module of the AdaptUI architecture is introduced.

Through the AdaptUIOnt's user model we also aim to allow users to configure
the adaptation process through the cited perspective, which is, without any required
physiological knowledge. During this configuration the user interacts with a
module called Capabilities Collector indicating several interaction requirements.
This module translates the user indications into a capabilities module. The
Capabilities Collector and all its features are detailed in
Section~\ref{sec:capabilities_collector}.

Regarding the context, several considerations were also discussed during the design
process. Context is mainly defined by its physiological conditions. Besides,
the \ac{gumo}~\citep{heckmann_gumogeneral_2005} ontology has been used to enrich the
model. The context model is extended in two different ways: on the one hand,
there is the sensors information and the combination of their measures (environment
data); on the other hand, a high-level information category built from the
combination of context and external pieces of information.

Devices are also modelled using different \ac{cobra}~\citep{cobra} classes. These
classes represent static and dynamic concepts of the device. Device's screen
resolution (\textit{DisplayScreenResolution}) is one of the static features of a
mobile device. On the contrary, the battery of the device changes with the use.
This is represented through the \textit{Battery} class, and is also used by
AdaptUIOnt to represent this concept. AdaptUIOnt remarks the dynamic characteristics
of these devices, which are usually not modelled and are vital for the result of
any kind of adaptation. Thus, several classes representing dynamic characteristics
of mobile devices are added.



\subsection{Designing the AdaptUIOnt Ontology}
\label{sec:model_detail}

The AdaptUIOnt ontology has been designed with two main considerations in mind.
First, taking into account that useful and practical (and non physiological)
capabilities of the user, context and device need to be represented in the model.
This is carried out by reviewing the literature models and making several
adaptations, modifications and contributions. For example, regarding the user
model, we use \ac{foaf}~\citep{foaf} and \ac{gumo}~\citep{heckmann_gumogeneral_2005} to
model the user most personal characteristics. Nevertheless, the user model is
not based on these ontologies. It is built under several assumptions made by
\citet{casas_user_2008} in their user profile taxonomy, with several modifications.
Regarding the three entities, the ontology understands each one as a set of
characteristics that define them. Thus, there is, for example, a \textit{User}
class with a relationship \textit{definedBy} which relates the concept of a user
with the characteristics that define him/her (the \textit{UserCharacteristics}
class). The same conceptualization is shared by the other two entities (see
Figure~\ref{fig:entities_characteristics}). This part of the ontology has been
called \textit{Entities Model}, and it is detailed in Section~\ref{sec:entities_model}.



\begin{figure}
\centering
\includegraphics[width=0.75\textwidth]{../figures/PDF/entities_characteristics}
\caption{\textit{User},
\textit{Context} and \textit{Device} classes (in yellow) and their main object
relationships. As is shown, these classes are defined by their corresponding
characteristics class (in green).}
\label{fig:entities_characteristics}
\end{figure}


Second, and based on the conclusions made by~\citet{gregor_designing_2002},
the proposed ontology aims to be aware of the possible dynamic variations of the
environment, which may affect to the three entities. Therefore, we have implemented
several auxiliary classes to collect all the temporary knowledge within the
environment. These classes, shown in Figure~\ref{fig:auxiliary_classes}, are
linked to the main classes and complete them through several triggered rules
(see Section~\ref{sec:adaptui_rules}). This part of the dynamic knowledge
representation of the AdaptUIOnt ontology has been called \textit{Dynamic Model},
and it is explained in Section~\ref{sec:dynamic_model}.


\begin{figure}
\centering
\includegraphics[width=1.0\textwidth]{../figures/PDF/auxiliary_classes.pdf}
\caption{\textit{UserAux}, \textit{ContextAux} and \textit{DeviceAux} classes
(in yellow) and their main datatype relationships.}
\label{fig:auxiliary_classes}
\end{figure}

As said before, AdaptUI allows users to manage the adaptation model through the
Capabilities Collector module. This idea, based on the work by~\citet{razmerita_ontology_based_2003},
allows users to participate during the model personalization and adaptation process. 
To this end, several classes have an \textit{isStatic} data property. This property
enables or disables the adaptation for the corresponding class depending on its
value (\textit{true} or \textit{false}). For example, the user might not want the
display brightness to be changed. A user profile where the brightness is configured
as static with the corresponding boolean value (\textit{adaptui:userdisplayBrightnessIsStatic})
means that during the adaptation process the corresponding rule (see the adaptation
rules set in Section~\ref{sec:adaptui_rules}) will evaluate this property
and finally avoid any change for the brightness parameter. The set of AdaptUIOnt
classes, object and datatype properties are shown through Figure~\ref{fig:classes},
Figure~\ref{fig:object_properties} and Figure~\ref{fig:datatype_properties}
respectively.

%CLASSES
\begin{figure}
\centering
\includegraphics[width=0.95\textwidth]{../figures/PDF/classes.pdf}
\caption{\textit{User} (left), \textit{Context} (centre)
and \textit{Device} (right) classes of the AdaptUI ontology.}
\label{fig:classes}
\end{figure}

%OBJECT PROPERTIES
\begin{figure}
\centering
\includegraphics[width=0.33\textwidth]{../figures/PDF/object_properties.pdf}
\caption{AdaptUI object properties.}
\label{fig:object_properties}
\end{figure}

%DATATYPE PROPERTIES
\begin{figure}
\centering
\includegraphics[width=0.65\textwidth]{../figures/PDF/datatype_properties.pdf}
\caption{AdaptUI datatype properties, not considering other ontologies. The left
group of properties are those related to
the \textit{UserCharacteristics} class.}
\label{fig:datatype_properties}
\end{figure}


\subsection{The \textit{Entities Model}}
\label{sec:entities_model}

After reviewing the literature in Chapter~\ref{cha:state_of_the_art} we found
that, for an appropriate adaptation of a user interface, there are three main
entities which must be represented in the domain: the user, the context and the
device. These concepts are semantically represented through the \textit{User},
\textit{Context} and \textit{Device} classes in the AdaptUIOnt ontology. But 
these three classes do not represent these entities alone. They are defined by 
their corresponding characteristics. These characteristics are represented through 
the \textit{UserCharacteristics}, \textit{ContextCharacteristics} and
\textit{DeviceCharacteristics} classes (see Figure~\ref{fig:user_characteristics_class}).
Together with the \textit{Adaptation} class, these seven classes form the Entities
Model, which is a conceptual group within the whole AdaptUIOnt model.
Figure~\ref{fig:entities_characteristics} shows the set of classes which form
the Entities Model.

\begin{figure}[H]
\centering
\includegraphics[width=1.0\textwidth]{../figures/PDF/user_characteristics_class.pdf}
\caption{The \textit{User} and the \textit{UserCharacteristics} classes.}
\label{fig:user_characteristics_class}
\end{figure}

Through the following sections the classes which belong to the Entities Model
are detailed. First, the \textit{UserCharacteristics} class is described in
Section~\ref{sec:user_characteristics_class}. Next, the \textit{ContextCharacteristics}
class is detailed (see Section~\ref{sec:context_characteristics_class}). Third,
a description of the \textit{DeviceCharacteristics} class is given in
Section~\ref{sec:device_characteristics_class}. Finally, the \textit{Adaptation}
class is detailed in Section~\ref{sec:adaptation_class}.


\subsubsection{The \textit{UserCharacteristics} Class}
\label{sec:user_characteristics_class}

The \textit{UserCharacteristics} class is one of the seven classes included in
the conceptual Entities Model. This class includes a series of subclasses which
build the knowledge about the user. Several user modelling ontologies are used
(i.e., \ac{foaf}~\citep{foaf} and \ac{gumo}~\citep{heckmann_gumogeneral_2005}). 
However, the strength of this class lies not on the representable knowledge 
through these classes, but in the way the knowledge about the user capabilities
(and disabilities) is represented. As explained in the introduction of this 
chapter, modelling physiological capabilities of users is troublesome and not 
practical. Several authors have tried to model user physiological characteristics~\citep{gregor_designing_2002}
\citep{razmerita_ontology_based_2003}~\citep{pereira_triple_2005}~\citep{persad_characterising_2007}
\citep{persad_cognitive_2007} and~\citep{skillen2012ontological}. Although their
systems may behave properly, there is still the issue of facing a coherent user
modelling process including user's capabilities. Not only because we lack
physiological background in the area, but also because different users may behave
in different ways even if they suffer from the same disability. 

To avoid this problem and to provide an ontology able to model user's 
capabilities, AdaptUIOnt's user's capabilities and disabilities knowledge is 
represented through the following classes:

\begin{itemize}
  \item \textit{Interface}: This category gathers input and output information
  about the user interaction preferences. Instead of modelling physiological
  capabilities regarding user's interaction abilities (e.g., sight capabilities),
  the model focuses in taking into account the user needs. For example, a user
  with a sight problem will not have to model a specific sight disability. This
  would require to consider several sight conditions and, for each one, different
  measures, ranges and classifications. Instead of that, there is the possibility
  for the user to model the Input/Output as voice and audio based interaction
  (by default the interaction is established as \textit{haptic}). This means that,
  by specifying these parameters, the system will understand that the user might
  suffer from a hearing loss condition or a sight disability.
  Table~\ref{tbl:user_characteristics_ontology} shows the interaction channels
  modelled by default in AdaptUIOnt.

  \item \textit{Audio} and \textit{Display}: These two classes model aspects
  about the use of the audio commands and volume controls, as well as different
  presentation parameters for the display, as brightness, contrast, orientation
  and magnification (see all the properties in Table~\ref{tbl:user_characteristics_ontology}).
  Thus, sight disabilities or, simply, sight problems due to context conditions
  (e.g., direct sunlight on the device screen) and hearing problems are faced by
  allowing the user to establish the default (or minimum) brightness, magnification,
  contrast, pitch, frequency and volume of the adaptation.
    
  \item \textit{Experience}: User experience with technology might be useful when
  executing adaptation rules. For examples, inexperienced users may need more
  instructions to run the profile (model) configuration process to add the
  corresponding knowledge about their capabilities.
  
  \item \textit{Other}: Several extra parameters (for example, the property
  \textit{has\_TTS}, which means that the user needs a tool which reads the text from
  the display). It also includes language and vibration related aspects.
  
  \item \textit{View}: User interfaces are composed of different views (\acs{gui} 
  elements) that are combined for representing different applications and services. 
  For each of these views (e.g., a Button) the model considers several properties 
  that the user can configure (i.e., size and colours). For example, users with 
  colour blindness can change the colours of the components before any adaptation 
  to specify the set of colours they are able to distinguish, or adjust a 
  minimum size for a button so the user is able to interact with it. Thus, in 
  the future adaptations, the adaptation rules will be aware of this user 
  particular need.
  
  \item \textit{Basic User Dimensions}: Extracted from the \ac{gumo} ontology
  \citep{heckmann_gumogeneral_2005}, this class models information about the user
  contact information. See Table~\ref{tbl:used_ontologies} in order to see the
  whole set of classes included under this class.
  
  \item \textit{Document}, \textit{SocialInstitution} and \textit{OnlineAccount}:
  Extracted from \ac{foaf}~\citep{foaf}, these classes complete several personal 
  and social characteristics of the user.
\end{itemize}



\begin{center}
\footnotesize
\begin{longtable}{l l l}
  
  \label{tbl:user_characteristics_ontology} \\
  \hline 
  \textbf{Subclass} 	& \textbf{Property name} 	& \textbf{Description}							\\
  \hline
  \textit{Interface}	& \textit{interfaceHasInput}	& This property models the possible input				\\
			& 				& methods for the user with the following		 		\\
			& 				& possibilities: \textit{gestures}, \textit{haptic}, \textit{voice\_control},\\
			&				& \textit{sensory}, \textit{only\_haptic}, \textit{only\_voice\_control}.\\
			& \textit{interfaceHasLanguage}	& Describes to define the desired language. 				\\
			& \textit{interfaceHasOutput}	& This property models the possible output  				\\
			& 				& methods for the user with the following 				\\
			& 				& possibilities: \textit{standard} (images, text, video  		\\
			&				& and sound), \textit{only\_audio}, \textit{only\_text}. 		\\
  
  \textit{Audio}	& \textit{audioHasApplicable}	& Describes if audio interaction is applicable				\\ 
			& 				& for the user. If \textit{false}, we infer that the user		\\
  			& 				&  might suffer from some hearing problems.				\\
  			& \textit{audioHasFrequency}	& Represents the preferred audio frequency. 				\\
  			& \textit{audioHasPitch}	& Describes the preferred pitch. 					\\
  			& \textit{audioHasVolume}	& Represents value which points out the 				\\
  			&				& desired audio volume.							\\
  			
  \textit{Display}	& \textit{displayHasApplicable}	& Describes the capability of the user to 				\\
			& 				& interact with the display. If \textit{false} we might 		\\
			& 				& understand that the user suffers from a 	 			\\
			&				& sight disability.							\\
			& \textit{displayHasBrightness}	& Represents value representing the 	 				\\
			&				& brightness value.							\\
			& \textit{displayHasContrast}	& Describes indicating the contrast value.				\\
			& \textit{displayHasMagnification}& Represents value which represents the 		 		\\ 
			&				& magnification degree needed for the user	 			\\
			&				& to properly see the display.						\\
			& \textit{displayHasOrientation}& Describes two options: \textit{landscape} or \textit{portrait}.  	\\
			& 				& This parameter indicates the preferred display 		 	\\
			&				& orientation for the user.						\\
  
  \textit{Experience}	& \textit{userHasExperience}	& A set of possible values to describe user’s 		 		\\
			& 				& experience with technology: \textit{standard}, 		 	\\
			&				& \textit{advanced}, \textit{not\_applicable}.				\\
  
  \textit{View}		& \textit{viewHasColor}		& Describes the colour for the view 					\\
			& 				& background.								\\
			& \textit{viewHasWidth}		& Represents value to determine the width of 				\\
			&				& the view.								\\
			& \textit{viewHasHeight}	& Describes the height of the view.					\\
			& \textit{viewHasTextColor}	& Represents value representing the colour 				\\
			&				& for the text.								\\
			& \textit{viewHasTextSize}	& Represents value representing the text size.				\\
  \hline 
\caption{UserCharacteristics data properties}
\end{longtable}
\end{center}


\subsubsection{The \textit{ContextCharacteristics} Class}
\label{sec:context_characteristics_class}

Usually, context is modelled considering that the data collected by sensors is
enough to characterize it. In AdaptUIOnt this kind of context is also modelled,
since sensor information is significantly relevant for being aware of the context
environment conditions. Thus, the information collected by sensors is represented
under the \textit{PhysicalEnvironment} and \textit{Location} classes, which are
classes from the \ac{gumo}~\citep{heckmann_gumogeneral_2005} ontology. Nevertheless,
the AdaptUIOnt ontology does not only model sensor related knowledge. There are
three extra classes which aim modelling high-level information about the
environment: \textit{LimitingConditions}, \textit{VirtualEnvironment} and
\textit{EnvironmentMetadata}. In the following lines a description of each class
is presented:

\begin{itemize}
 \item \textit{PhysicalEnvironment}: Environment information collected from
 sensors (e.g., absolute location, available resources, light and noise conditions).
 
 \item \textit{Time} and \textit{Location}: Both classes are used to characterize
 each user and device in a temporal and location context. Both entities are linked
 to these context variables through the \textit{userIsIn} and \textit{deviceIsIn}
 object properties (see Figure~\ref{fig:object_properties}).
 
 \item \textit{LimitingConditions}: Instead of modelling a set of particular
 activities we consider several context situations that might impede the interaction
 with the user. These situations are modelled as different groups regarding the
 capabilities that they might affect.
 
 \item \textit{VirtualEnvironment}: Combining the knowledge of the categories
 above, it is possible to extract high-level information. For example, sensing
 that there is a light at the office, it is possible to infer that there are
 people working. Thus, we avoid the use of other sensors to indicate this
 activity.
 
 \item \textit{EnvironmentMetadata}: Environment knowledge is associated to
 sensors. A sensor can provide information about the temperature (23 ºC). But
 this information by itself is poor in a context-aware system. Environment metadata
 can describe and enrich this knowledge, providing time and location data. For
 example, ``the current temperature at 12:00 AM in Bilbao is 13 ºC''.
\end{itemize}


Table~\ref{tbl:context_characteristics_ontology} shows the main datatype properties
of the \textit{ContextCharacteristics} class.

\begin{table}[H]
  \caption{ContextCharacteristics data properties}
 \label{tbl:context_characteristics_ontology}
\footnotesize
\centering
 \begin{tabular}{l l l}
  \hline 
  \textbf{Subclass} 	& \textbf{Property name} 	& \textbf{Description}					\\
  \hline
  \textit{Location}	& \textit{hasRelativeLocation}	& Represents relative locations.			\\
			& \textit{hasAbsoluteLocation}	& Describes \textit{longitude} and \textit{latitude}.	\\
  \textit{Light}	& \textit{contextHasLight}	& Describes the amount of \ac{lx} in the		\\
			& 				& environment.						\\
  \textit{Noise}	& \textit{contextHasNoise}	& Represents the amount of \acp{db} in 		\\
			& 				& the environment.					\\
  \textit{Time}		& \textit{hasTimeValue}		& The current time.					\\
  \textit{LimitingConditions}& \textit{hasMovementRestriction}&							\\
  \hline
  
\end{tabular}
\end{table}



\subsubsection{The \textit{DeviceCharacteristics} Class}
\label{sec:device_characteristics_class}

The device model is also built over several useful classes from other ontologies.
The most important characteristic of this class consists in modelling dynamic
information about the device regarding the adaptation. For example, low battery
levels might be considered risky by the AdaptUI system, as there is the possibility
that the device turns off during the process. Device capabilities are categorized
as follows:

\begin{itemize}
 \item \textit{Software}, which encompasses different software aspects of the
 device (i.e., the \ac{os} platform). 
 
 \item \textit{Hardware}, designed to model information about the current status
 of different capabilities (i.e., available battery and memory).
\end{itemize}


Table~\ref{tbl:device_characteristics_ontology} shows the main datatype properties
of the \textit{DeviceCharacteristics} class.


\begin{table}
  \caption{DeviceCharacteristics data properties.}
 \label{tbl:device_characteristics_ontology}
\footnotesize
\centering
 \begin{tabular}{l l l}
  \hline 
  \textbf{Subclass} 	& \textbf{Property name} 	& \textbf{Description}		\\
  \hline
  \textit{Brightness}	& \textit{deviceHasBrightness}	& Describes the current		\\
			& 				& device’s brightness.		\\
  \textit{Contrast}	& \textit{deviceHasContrast}	& Represents the current 	\\
  			& 				& device’s contrast.		\\
  \textit{Volume}	& \textit{deviceHasVolume}	& Describes the current		\\
   			& 				& device’s volume.		\\
  \textit{Processor}	& \textit{deviceHasHWCores}	& Models the number 		\\
			& 				& of the device’s cores.	\\
  \textit{OS}		& \textit{deviceOSHasVersion}	& Indicates the current		\\
			& 				& \ac{os} version.		\\
  \textit{Acceleration}	& \textit{deviceHasAcceleration}& Represents the current 	\\
			& 				& X, Y, Z acceleration.		\\
  \textit{DeviceScreen,	Processor,}& \textit{hasFactoryValue}& Maximum values for 	\\
\textit{Orientation, DeviceMemory,}& 			& the elements under the  	\\
\textit{Battery, DeviceScreenResolution,} & 		& Sub-class column.  		\\
\textit{DeviceStorage} 	& 				& 				\\
  \hline

\end{tabular}
\end{table}


\subsubsection{The \textit{Adaptation} Class}
\label{sec:adaptation_class}

The last class included in the Entities Model is the \textit{Adaptation} class.
This class represents the final stage of the whole adaptation process. This means
that, after the adaptation process the results will be represented through an
individual (or instance) of this class. Therefore, the AdaptUI platform will
semantically request the corresponding adaptation for the user interface to this
class. As can be seen in Figure~\ref{fig:entities_characteristics}, the
\textit{Adaptation} class is linked to the other classes of the Entities Model
(\textit{User}, \textit{Context} and \textit{User}) through the \textit{adaptationIsDefinedBy}
object property. Thus, future semantic requests are allowed searching for a
specific user capability, context situation or device characteristics.
Table~\ref{tbl:adaptation_properties} shows the datatype properties of the
\textit{Adaptation} class.


\begin{table}
  \caption{\textit{Adaptation} class datatype properties.}
 \label{tbl:adaptation_properties}
\footnotesize
\centering
 \begin{tabular}{l l}
  \hline 
  \textbf{Datatype property} 			& \textbf{Description}				\\
  \hline
  \textit{adaptationBrightnessHasValue}		& Describes the final brightness value to be 	\\
						& configured in the device. 			\\
  \textit{adaptationVolumeHasValue}		& Represents the final volume value to be 	\\
						& configured in the device. 			\\
  \textit{adaptationButtonHasSize}		& Describes the final size value for a Button. 	\\
  \textit{adaptationButtonHasBackgroundColor}	& Represents the final background colour for 	\\
						& a Button.					\\
  \textit{adaptationButtonHasTextSize}		& Describes the final text size for a Button.	\\
  \textit{adaptationButtonHasTextColor}		& Represents the final text colour for a Button.\\
  \textit{adaptationEditTextHasSize}		& Describes the final size value for a EditText.\\
  \textit{adaptationEditTextHasBackgroundColor}	& Represents the final background colour for 	\\ 
						& a EditText.					\\
  \textit{adaptationEditTextHasTextSize}	& Describes the final text size for a EditText.	\\
  \textit{adaptationEditTextHasTextColor}	& Represents the final text colour for a EditText.\\
  \textit{adaptationTextViewHasSize}		& Describes the final size value for a TextView.\\
  \textit{adaptationTextViewHasBackgroundColor}	& Represents the final background colour for 	\\
						& a TextView.					\\
  \textit{adaptationTextViewHasTextSize}	& Represents the final text size for a TextView.\\
  \textit{adaptationTextViewHasTextColor}	& Describes the final text colour for 		\\
						& a TextView.		 			\\
  \hline
  
\end{tabular}
\end{table}


% \section*{}


\subsection{Incoherence and Activities}
\label{sec:incoherence}

During the design of the AdaptUI ontology we have considered how the three
main entities (user, context and device) interact with each other. Modelling
these entities and being aware of the interactions that occur among them help
us to deduce the best adaptation for the user in each case. However, there are
several situations where the adaptation process is not so obvious. These situations
are defined by the activities that are being carried out within the environment.

\citet{persad_characterising_2007}~\citep{persad_cognitive_2007}
consider that activities need to be taken into account. They describe Human
Factors and Ergonomic theory as four components: the user, the product, the context
and the activities over time that constitutes the interaction.
\citet{hong_context_aware_2009} classify context conflicts into several categories:

\begin{itemize}
 \item Sensing conflict: Not matching results from several physical data sources.
 
 \item Service resource conflict: The lack of resources in a service offering
 process may provoke several conflicts.
 
 \item User preference conflict: Users whose profiles or preferences are different
 but having the same context situation may also result in context conflict.
\end{itemize}

During the designing process of AdaptUI, we asked ourselves if it would be enough
to consider just the user and his/her capabilities within the current context.
Thus, several hypothetical scenarios were studied:

\begin{itemize}
 \item A user suffers from a visual impairment. This disability obstructs
 the user from seeing the application content properly. Then the adaptation
 will intercede to facilitate another interaction channel for the user, e.g.,
 by voice recognition and control. The problem is that there are situations
 in which a common adaptation from the system will not be appropriate.
 For example, if the user is in a place where silence is essential (i.e., a
 library, a hospital or in an exam), an audio interaction based communication
 could not be appropriate. 
 
 \item A user who sees perfectly well interacts with the application’s
 default user interface. If we avoid a situation in which the user is driving
 a visual/touch based adaptation could put the user in risk, as he/she would
 need to look at the display and use his/her hands.
 
 \item Another user is at home, and he/she does not suffer from any severe
 disability. At 01:00 pm he/she starts cooking. The application requests
 user attention for several tasks. This situation might be risky if the adaptation
 requests the user attention while he/she has, for example, oil in the pot, or
 he/she is manipulating knives.
\end{itemize}

These examples show several situations where users are involved in tasks that
contradict the current context and user capabilities. Adaptation incoherence is
defined by several environment parameters that induce the platform to perform a
certain adaptation for the current conditions. However, the result of this
adaptation, although it can be aligned with the context characteristics, can be
incoherent.

Therefore, we need something more to characterize the current situation that
involves these three entities: activities. Activities help us to understand the
current user, context and device situation. In other words, it enriches the
environment information.

Requiring the use of the hands, being at a certain location (like a library, where
people has to be in silence), or demanding the user attention are several examples
of situations which may represent some risks that we have to take into account
when we face a context modelling problem. For example, driving or cooking restricts
user capabilities momentarily. Hence, we can state that these activities impede
the user. As is difficult to model every possible activity that the user performs,
in AdaptUI we present a class (\textit{LimitingConditions}) that models abstract
groups of activities:

\begin{itemize}
 \item Activities that limit the use of the hands.
 \item Activities that limit the use of the voice.
 \item Activities that limit the user sight capability.
 \item Activities that limit the user attention.
 \item Activities that limit the user movement.
 \item Combinations of these activities.
\end{itemize}

\subsection{The \textit{Dynamic Model}}
\label{sec:dynamic_model}

The proposed solution addresses several issues of several modelling approaches
found in the literature. Following the perspective of~\citet{fischer_user_2001}
we consider that the modelled entities are not static at all. They change through
time due to their interaction. To express this concept of \textit{dynamic model}
we have implemented several auxiliary classes:

\begin{itemize}
 \item \textit{UserAux}: This class is helpful when a certain context situation
 impedes a user capability. Updated by the pre-adaptation rules this class is used
 as intermediary between the \textit{Adaptation} class and the \textit{ContextAux}
 class, where the classification of the context collected information is modelled.
 As is shown in Table~\ref{tbl:aux_classes_data_properties}, it models several user
 dynamic capabilities.
 
 \item \textit{ContextAux}: Context is considered in a different way. As context
 information comes from sensors, we have to translate the different incoming data
 to a more descriptive language. Thus, if a value of 35,000 lux is collected (as
 a brightness value of the \textit{ContextCharacteristics} class) we modify the
 contextAuxHasLightLevel data property with the \textit{direct\_sunlight} value (see
 Table~\ref{tbl:aux_classes_data_properties}). Therefore, it is possible to work
 with more meaningful data. The same occurs with the contextAuxHasNoiseLevel
 data property. Table~\ref{tbl:luminance} and Table~\ref{tbl:sounds} show the
 different classifications for light and noise levels used for AdaptUI.
 
 \item \textit{DeviceAux}: Following the same approach, this class deals with the
 dynamic capabilities of the device.
\end{itemize}

Working with sensor data opens new fronts regarding the AdaptUI platform. For
example, fuzzy reasoning would help to refine the collected information. This
is discussed in the Future Work section (see Section~\ref{sec:future_work}).


\begin{center}
\footnotesize
\begin{longtable}{l l l}
  \label{tbl:aux_classes_data_properties} \\
  \hline 
  \textbf{Class} 	& \textbf{Property name} 		& \textbf{Description}			\\
  \hline
  \textit{UserAux}	& \textit{userAuxDIsplayHasApplicable}	& Models the applicability of display 	\\
			& 					& adaptations for the user. There are 	\\
			& 					& two different scenarios: 1) in the 	\\
			& 					& first one, the user might suffer  	\\
			&					& from a disability that makes 		\\
			&					& impossible for him/her to interact 	\\
			&					& with a display. In this case Display 	\\
			& 					& is not applicable for this user; 2)	\\
			& 					& on the contrary, the user can specify	\\
			&					& that he/she does not want the display	\\
			& 					& to be adapted. In any case the value 	\\
			&					& of this property will determine if  	\\	
			& 					& the rules need to consider Display.	\\
			& \textit{userAuxAudioHasApplicable}	& Similar to the previous property, 	\\
			& 					& this one has the same effect for 	\\
			&					& audio adaptations.			\\
			& \textit{userAuxHasDisplayBrightness}	& Depending on the value of the 	\\
			&					& \textit{UserCharacteristics}:		\\
			& 					& \textit{userDisplayBrightnessIsStatic}\\
			&					& property, the corresponding rule 	\\
			& 					& will update this value indicating if 	\\
			& 					& the brightness should be considered 	\\
			&					& for the adaptation process.		\\
			& \textit{userAuxHasExperience}		& Represents user’s experience with 	\\
			& 					& technology: \textit{easy}, \textit{expert}, \textit{not\_possible}, 	\\
			&					& \textit{standard}.			\\
			& \textit{userAuxHasRestriction}	& User's activities are considered for	\\
			&					&  adaptation. Hence, a Boolean	\\
			& 					& value is modelled in this property 	\\
			& 					& to indicate so.			\\
  \textit{ContextAux}	& \textit{contextAuxHasLightLevel}	& Represents several light classifications: 				\\
			& 					& \textit{clear\_night}, \textit{dark\_overcast}, \textit{daylight}, 	\\
			& 					& \textit{direct\_sunlight}, \textit{living\_room},  			\\
			& 					& \textit{moonless\_clear}, \textit{moonless\_overcast},  		\\ 
			& 					& \textit{office\_hallway}, \textit{office\_lightning}, 		\\
			&					& \textit{overcast\_day}, \textit{sunrise}, \textit{twilight} 		\\
			& \textit{contextAuxHasNoiseLevel}	& Represents several noise 		\\
			&					& classifications:			\\
			&					& \textit{absolute\_threshold\_of\_hearing}, 				\\
			& 					& \textit{breathing}, \textit{building\_work}, \textit{conversation}, 	\\
			& 					& \textit{factory}, \textit{gig}, \textit{jackhammer}, 			\\ 
			& 					& \textit{leaves\_murmuring}, \textit{library}, \textit{office}, 	\\
			&					& \textit{traffic}, \textit{train}, \textit{truck}, \textit{whispering}.\\
  \textit{DeviceAux}	& \textit{deviceAuxBatteryIsSufficient}& Based in Table~\ref{tbl:batteries}, indicates \\
  			& 					& whether the adaptation should be   	\\
  			& 					& performed considering the current 	\\
  			&					& battery level.			\\
  			& \textit{deviceAuxHasBrightness}	& Describes the current brightness 	\\
  			& 					& level of the device’s screen.		\\
  \hline
\caption{Auxiliary classes' data properties.}\\
\end{longtable}
\end{center}



\begin{table}
  \caption{Luminance provided under various conditions~\citep{luminance}.}
 \label{tbl:luminance}
\footnotesize
\centering
 \begin{tabular}{l l l}
  \hline 
  \textbf{Brightness} & \textbf{Surfaces illuminated by}		& \textbf{Ontology value}	\\
  \textbf{(measured) in \ac{lx}}&					&				\\
  \hline
  0.0001		& Moonless, overcast night sky (starlight)	& \textit{moonless\_overcast}	\\
  0.002 		& Moonless clear night sky with air-glow	& \textit{moonless\_clear}	\\
  0.27-1.0		& Full moon on a clear night			& \textit{full\_moon}		\\
  1.0-3.4		& Dark limit of civil twilight under a clear sky& \textit{twilight}		\\
  3.4-50		& Family living room lights			& \textit{living\_room}		\\
  50-80 		& Office building hallway/toilet lighting	& \textit{office\_hallway}	\\
  80-100		& Very dark overcast day			& \textit{dark\_overcast}	\\
  320-500		& Office lighting				& \textit{office\_lightning}	\\
  500-1,000		& Overcast day; typical TV studio lighting	& \textit{overcast}		\\
  1,000-25,000		& Full daylight (not direct sun)		& \textit{daylight}		\\
  25,000-130,000	& Direct sunlight (latter figure is 		& \textit{direct\_sunlight}	\\
			& above atmosphere)				& 				\\
  \hline

\end{tabular}
\end{table}


In order to describe the whole detailed model and how the main classes are related
to each other, Figure \ref{fig:flow_diagram} shows how the knowledge flows through
the AdaptUI platform. First, the three main classes of the \textit{Entities Model}
are populated with the information about the user, the context and the device.
Then, the pre-adaptation rules are triggered and updates classifies and updates
the collected knowledge into intermediate knowledge. This knowledge is represented
in the \textit{UserCharacteristics}, \textit{ContextCharacteristics} and
\textit{DeviceCharacteristics} classes. Finally, the \textit{Adaptation} class
requests the processed knowledge and through the adaptation rules the final
adaptation is sent to the user. Additionally, within the user model the interaction
model collects information about the interaction, updating the \textit{UserAux}
class if needed. This brings the execution of the rules again, which means that
a new result is generated.


\begin{table}[H]
  \caption{Most common sound intensity levels modelled by default in AdaptUI.}
 \label{tbl:sounds}
\footnotesize
\centering
 \begin{tabular}{l r}
  \hline 
  \textbf{Ontology value}	& \textbf{\ac{db}}\\
  \hline
  Absolute threshold of hearing	& 0	\\
  Breathing			& 10 	\\
  Leaves murmuring		& 20	\\
  Library			& 40	\\
  Office			& 50	\\
  Conversation			& 60	\\
  Traffic			& 70	\\
  Factory			& 80	\\
  Truck				& 90	\\
  Train				& 100	\\
  Construction			& 110	\\
  Rock gig			& 120	\\
  Jackhammer			& 130	\\
  \hline

\end{tabular}
\end{table}


\begin{table}[H]
  \caption{Battery percentage and ontology values for AdaptUI.}
 \label{tbl:batteries}
\footnotesize
\centering
 \begin{tabular}{c l}
  \hline 
  \textbf{Battery (\%)} 	& \textbf{Ontology value}	\\
  \hline  
  $x\leq15$			& Not sufficient		\\
  $15<x\leq50$			& Sufficient			\\
  $50<x\leq100$			& Optimal			\\
  \hline

\end{tabular}
\end{table}



\subsection{Conclusions}
\label{sec:model_conclusions}

During the previous sections the AdaptUIOnt ontology, which forms part of the two
main bases of the AdaptUI platform, has been described. The most significant
characteristic of the ontology is that allows the representation of the knowledge
about what we consider the three main entities in a user interface adaptation
domain: the user, the context, and the device. 

The first trouble when designing the ontology appeared when the user capabilities
modelling was needed. As we lack the required physiological knowledge in this area,
we believe that using physiological information of the user capabilities would
not be practical. Thus, an abstraction of the conceptualization of the model was
performed. Instead of consider the physiological factors that allow a user to
perform several interactions, the AdaptUIOnt model centres its focus in the needs
of the user to carry out these interactions. This is significant, as it allows
us to avoid these capabilities explicitly. Besides, the presented ontologies
uses several extendedly used ontologies to enrich the information about the three
entities. Table~\ref{tbl:used_ontologies} details the most important classes
imported in AdaptUIOnt.

The ontology has been conceptually divided into two different parts. The first
one gathers the main classes, those which directly represent knowledge about
the main entities. In this case, this part of the ontology has been called
Entities Model, and its composed by the \textit{User}, \textit{Context},
\textit{Device}, \textit{UserCharacteristics}, \textit{ContextCharacteristics},
\textit{DeviceCharacteristics} and \textit{Adaptation}. Each main entity is
defined by a class which models its characteristics. Thus, the \textit{User}
class is directly related to the \textit{UserCharacteristics} class through a
\textit{isDefinedBy} object property. The same procedure is followed by the other
two main entities. The \textit{Adaptation} class, however, just represents the
final stage of the whole adaptation process. Therefore, after the corresponding
reasoning (detailed in the following sections) the AdaptUI platform will
semantically requests the adaptation information represented by it.
